# Put R code below.
residual['base'] <- with(sportHeights, height[sport == 'baseball'] - group_mean[sport == 'baseball'])
boxplot(residual)
# Put R code below.
residual['base'] <- with(sportHeights, height[sport == 'baseball'] - group_mean[sport == 'baseball'])
boxplot(residual)
residual
# Put R code below.
residual['base'] <- with(sportHeights, height[sport == 'baseball'] - group_mean[sport == 'baseball'])
boxplot(residual)
residual
# Put R code below.
residual['base'] <- with(sportHeights, height[sport == 'baseball'] - group_mean[sport == 'baseball'])
boxplot(residual)
residual
# Put R code below.
residual['base'] <- with(sportHeights, height[sport == 'baseball'] - group_mean[sport == 'baseball'])
boxplot(residual)
length(residual)
# Put R code below.
residual['base'] <- with(sportHeights,height - group_mean)
boxplot(residual)
length(residual)
# Put R code below.
residual['base'] <- with(sportHeights,height - group_mean ~ sport)
# Put R code below.
test <- oneway.test(height~sport, data = sportHeights, var.equal = T)
# Put R code below.
test <- oneway.test(height~sport, data = sportHeights, var.equal = T)
test
# Put R code below.
residual['base'] <- with(sportHeights,height - group_mean )
resid(test)
boxplot(residual)
length(residual)
# Put R code below.
#residual['base'] <- with(sportHeights,height - group_mean )
#resid(test)
#boxplot(residual)
#length(residual)
sportHeights['residuals'] <- with(sportHeights, height - group_mean)
sportHeights
# Put R code below.
#residual['base'] <- with(sportHeights,height - group_mean )
#resid(test)
#boxplot(residual)
#length(residual)
sportHeights['residuals'] <- with(sportHeights, height - group_mean)
boxplot(sportHeights$residuals~sportHeights$sport)
# Put R code below.
test <- oneway.test(height~sport, data = sportHeights, var.equal = F)
# Put R code below.
oneway.test(height~sport, data = sportHeights, var.equal = F)
knitr::opts_chunk$set(echo = TRUE)
oneway.test(Lifetime ~ Diet, data = case0501, var.equal = T)
knitr::opts_chunk$set(echo = TRUE)
library(Sleuth3)
qplot(Diet, Lifetime, data = case0501, geom = "boxplot")
knitr::opts_chunk$set(echo = TRUE)
library(Sleuth3)
library(ggplot2)
qplot(Diet, Lifetime, data = case0501, geom = "boxplot")
oneway.test(Lifetime ~ Diet, data = case0501, var.equal = F)
oneway.test(Lifetime ~ Diet, data = case0501, var.equal = T)
knitr::opts_chunk$set(echo = TRUE)
library(Sleuth3)
library(ggplot2)
# This is an R comment. Add your R code below.
#avgHeights
sportMeans <- tapply(sportHeights$height, sportHeights$sport, mean)
totalMean <- mean(sportMeans)
sportHeights$overall_mean <- with(sportHeights, mean(height))
sportHeights$group_mean <- with(sportHeights, ave(height,sport))
head(sportHeights)
# Try without assuming equal variance
oneway.test(Lifetime ~ Diet, data = case0501, var.equal = F)
?reorder
geom_boxplot?
?geom_boxplot
knitr::opts_chunk$set(echo = TRUE)
library(Sleuth3)
library(ggplot2)
bearing <- read.csv(file = 'bearings.csv')
print(paste("data is stored in a", typeof(bearing)))
qplot(Compound, Time , data = bearing, geom = 'boxplot')
#length(bearing$Time[bearing$Compound == 'III'])
dietData <- case0501
# METHOD - Use Tukey Kramer adjustment as we are doing all pairwise comparisons
#head(dietData)
fitDiets <- aov(Lifetime ~ Diet,data = dietData)
diets <- TukeyHSD(fitDiets, ordered = TRUE)
diets
dietData <- case0501
# METHOD - Use Tukey Kramer adjustment as we are doing all pairwise comparisons
#head(dietData)
fitDiets <- aov(Lifetime ~ Diet,data = dietData)
diets <- TukeyHSD(fitDiets)
diets
(1-0.05/6)
(1-0.05/21)
1-(1-0.05/21)
(1-0.01/21)
library(broom)
library(car)
library(ggplot2)
library(ggExtra)
packages.install('ggExtra')
install.packages(c('broom', 'car', 'ggplot2', 'ggExtra', 'MASS', 'reshape'))
install.packages(c("broom", "car", "ggplot2", "ggExtra", "MASS", "reshape"))
library(broom)
library(car)
library(ggplot2)
library(ggExtra)
library(MASS)
library(reshape)
MLB <- read.csv("MLB.csv")
library(broom)
library(car)
library(ggplot2)
library(ggExtra)
library(MASS)
library(reshape)
MLB <- read.csv("MLB.csv")
head(MLB)
qplot(HR, R, data = MLB)
qplot(BB, R, data = MLB)
qplot(SO, R, data = MLB)
MLB_fit <- lm(R ~ HR + BB + SO, data = MLB)
summary(MLB_fit)
MLB_diag <- augment(MLB_fit)
head(MLB_diag)
qplot(HR, .resid, data = MLB_diag) +
geom_hline(aes(yintercept=0))
qplot(BB, .resid, data = MLB_diag) +
geom_hline(aes(yintercept=0))
qplot(SO, .resid, data = MLB_diag) +
geom_hline(aes(yintercept=0))
qplot(.fitted, .resid, data = MLB_fit) +
geom_hline(aes(yintercept=0))
qplot(1:28, .hat, data = MLB_diag)
MLB_diag[MLB_diag$.hat > 0.2, ] #Check which points have high leverage
MLB_diag[MLB_diag$.hat > 0.3, ]
qplot(1:28, .cooksd, data = MLB_diag)
MLB[MLB_diag$.cooksd > 0.6, ] #Check which points have high influence
knitr::opts_chunk$set(echo = TRUE)
qplot(Fe, loss, data = corrosion) + geom_smooth(method = "lm")
knitr::opts_chunk$set(echo = TRUE)
data(corrosion, package = "faraway") # Load data from faraway package corrosion
# Look at data
?faraway::corrosion # Learn about dataset
qplot(Fe, loss, data = corrosion)
fit <- lm(loss~Fe, data = corrosion)
summary(fit)
qplot(Fe, loss, data = corrosion) + geom_smooth(method = "lm")
fitAug <- augment(fit)
qplot(Fe,.resid, data = fitAug)
FitSMM <- lm(loss~factor(Fe), data = corrosion)
anova(fit, FitSMM)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
fit <- lm(dist ~ speed, data = cars)
summary(fit)
augFit <- augment(fit)
mean(fit$residuals)
qplot(speed, .resid, data = augFit, main = 'Speed VS Residuals')
qplot(.fitted, .resid, data = augFit, main = 'Fitted VS Residuals')
augFit
augFit <- augment(fit)
mean(fit$residuals)
qplot(speed, .resid, data = augFit, main = 'Speed VS Residuals')
qplot(.fitted, .resid, data = augFit, main = 'Fitted VS Residuals')
augFit
library(broom)
library(car)
library(ggplot2)
library(ggExtra)
library(MASS)
library(reshape)
MLB <- read.csv("MLB.csv")
head(MLB)
qplot(HR, R, data = MLB)
qplot(BB, R, data = MLB)
qplot(SO, R, data = MLB)
MLB_fit <- lm(R ~ HR + BB + SO, data = MLB)
summary(MLB_fit)
MLB_diag <- augment(MLB_fit)
head(MLB_diag)
mu1 <- matrix(c(0,0))
sigma1 <- matrix(c(1, 0, 0, 1), ncol = 2)
X1 <- mvrnorm(n = 250, mu = mu1, Sigma = sigma1)
p <- qplot(V1, V2, data = as.data.frame(X1)) +
xlab(expression(X[1])) + ylab(expression(X[2]))
ggExtra::ggMarginal(p, type = "histogram")
View(X1)
mu1 <- matrix(c(0,0))
sigma2 <- matrix(c(1, 0.9, 0.9, 1), ncol = 2)
X2 <- mvrnorm(n = 250, mu = mu1, Sigma = sigma2)
p2 <- qplot(V1, V2, data = as.data.frame(X2)) + xlab(expression(X[1])) + ylab(expression(X[2]))
ggExtra::ggMarginal(p2, type = "histogram")
mu1 <- matrix(c(0,0))
sigma1 <- matrix(c(1, 0, 0, 1), ncol = 2)
X1 <- mvrnorm(n = 250, mu = mu1, Sigma = sigma1)
p <- qplot(V1, V2, data = as.data.frame(X1)) + xlab(expression(X[1])) + ylab(expression(X[2]))
#ggExtra::ggMarginal(p, type = "histogram")
mu1 <- matrix(c(0,0))
sigma1 <- matrix(c(1, 0, 0, 1), ncol = 2)
X1 <- mvrnorm(n = 250, mu = mu1, Sigma = sigma1)
p <- qplot(V1, V2, data = as.data.frame(X1)) + xlab(expression(X[1])) + ylab(expression(X[2]))
ggExtra::ggMarginal(p, type = "histogram")
mu1 <- matrix(c(0,0))
sigma2 <- matrix(c(1, 0.9, 0.9, 1), ncol = 2)
X2 <- mvrnorm(n = 250, mu = mu1, Sigma = sigma2)
p2 <- qplot(V1, V2, data = as.data.frame(X2)) + xlab(expression(X[1])) + ylab(expression(X[2]))
ggExtra::ggMarginal(p2, type = "histogram")
View(X2)
View(X2)
mu1 <- matrix(c(0,0))
sigma2 <- matrix(c(1, 0.9, 0.9, 1), ncol = 2)
X2 <- mvrnorm(n = 250, mu = mu1, Sigma = sigma2)
p2 <- qplot(V1, V2, data = as.data.frame(X2)) + xlab(expression(X[1])) + ylab(expression(X[2]))
ggExtra::ggMarginal(p2, type = "histogram")
mu1 <- matrix(c(0,0))
sigma2 <- matrix(c(1, 0.9, 0.9, 1), ncol = 2)
X2 <- mvrnorm(n = 250, mu = mu1, Sigma = sigma2)
p2 <- qplot(V1, V2, data = as.data.frame(X2)) + xlab(expression(X[1])) + ylab(expression(X[2]))
ggExtra::ggMarginal(p2, type = "histogram")
fitmodel <- function(X1, X2, beta0, beta1, beta2){
n <- length(X1)
Y <- beta0 + beta1*X1 + beta2*X2 + rnorm(n, 0, 1) # Generate/calculate response
fit <- lm(Y ~ X1 + X2) # Fit the model
fit$coefficients # Return estimated coefficient values
}
# Step 1
beta0 <- 0.5 # define beta_0
beta1 <- 0.3 # define beta_1,
beta2 <- 0.7 # define beta_2
# Step 2
mu <- matrix(c(0,0)) # Set means for X_1, X_2
sigma1 <- matrix(c(1, 0, 0, 1), ncol = 2) # Cov Matrix: Cov(X_1, X_2) = 0
# Step 3
set.seed(1822) # Francis Galton born, invented regression concept
n <- 250
X <- mvrnorm(n, mu=c(0,0), Sigma=sigma1)
X1 <- X[,1]
X2 <- X[,2]
# Step 7
beta_estimates <- replicate(10000, fitmodel(X1, X2, beta0, beta1, beta2))
View(beta_estimates)
View(beta_estimates)
# Display results
qplot(beta_estimates[1,]) + ylab("") +
theme(axis.ticks = element_blank(), axis.text.y = element_blank()) +
xlab(expression(beta[0]))
sd(beta_estimates[1,])
# Uncorrelated
sigma1 <- matrix(c(1, 0, 0, 1), ncol = 2) # Cov Matrix: Cov(X_1, X_2) = 0
# Step 3
set.seed(1822) # Francis Galton born, invented regression concept
n <- 250
X <- mvrnorm(n, mu=c(0,0), Sigma=sigma1)
X1 <- X[,1]
X2 <- X[,2]
# Step 7
uncor_beta_estimates <- replicate(10000, fitmodel(X1, X2, beta0, beta1, beta2))
# Correlated
sigma2 <- matrix(c(1, 0.9, 0.9, 1), ncol = 2)
# Step 3
set.seed(1822) # Francis Galton born, invented regression concept
n <- 250
X <- mvrnorm(n, mu=c(0,0), Sigma=sigma2)
X1 <- X[,1]
X2 <- X[,2]
# Step 7
cor_beta_estimates <- replicate(10000, fitmodel(X1, X2, beta0, beta1, beta2))
results <- cbind(t(uncor_beta_estimates), t(cor_beta_estimates))
gg <- apply(results, 2, var)
gg[4:6]/gg[1:3]
colnames(results) <- paste("hat(beta)[", rep(0:2, 2), "]:", rep(c("Uncorrelated", "Correlated"), each = 3), sep = "")
results <- melt(results)
colnames(results) <- c("index", "Param", "Estimate")
results$beta <- sapply(strsplit(as.character(results$Param), ":"), "[[", i = 1)
results$data <- factor(sapply(strsplit(as.character(results$Param), ":"), "[[", i = 2), levels = c("Uncorrelated", "Correlated"))
qplot(Estimate, data = results) +
facet_grid(data ~ beta, labeller = label_parsed) +
ylab("") +
theme(axis.ticks = element_blank(), axis.text.y = element_blank())
View(results)
vif(MLB_fit)
cor(MLB[,2:4])
sigma2 <- matrix(c(1, 0.9, 0.9, 1), ncol = 2) # Cov Matrix: Cov(X_1, X_2) = 0.9
set.seed(1822)
n <- 250
X <- mvrnorm(n, mu=c(0,0), Sigma=sigma2)
X1 <- X[,1]
X2 <- X[,2]
Y <- beta0 + beta1*X1 + beta2*X2 + rnorm(n, 0, 1) # Generate/calculate response
fit_cor <- lm(Y ~ X1 + X2) # Fit the model
vif(fit_cor)
knitr::opts_chunk$set(echo = TRUE)
library(broom)
library(ggplot2)
library(MASS)
library(Sleuth3)
help(case0902)
head(case0902)
fit <- lm(brain ~ c(Body, Gestation, Litter) , data = case0902)
fit <- lm(Brain ~ c(Body, Gestation, Litter) , data = case0902)
fit <- lm(Brain ~ Body + Gestation + Litter , data = case0902)
summary(fit)
help(case0902)
(case0902)
augFit <- augment(fit)
head(augFit)
augFit <- augment(fit)
head(augFit)
max(augFit['.hat'])
augFit <- augment(fit)
head(augFit)
augFit[.hat == max(augFit['.hat'])]
augFit <- augment(fit)
head(augFit)
augFit[augFit['.hat'] == max(augFit['.hat'])]
augFit <- augment(fit)
head(augFit)
augFit[augFit$.hat == max(augFit['.hat'])]
augFit <- augment(fit)
head(augFit)
augFit[augFit$.hat == max(augFit$.hat)]
augFit <- augment(fit)
head(augFit)
#augFit[augFit$.hat == max(augFit$.hat)]
max(augFit$.hat)
augFit <- augment(fit)
head(augFit)
max_lev <- max(augFit$.hat)
augFit[augFit$.hat == max_lev]
augFit <- augment(fit)
head(augFit)
max_lev <- max(augFit$.hat)
augFit == max_lev
augFit <- augment(fit)
head(augFit)
max_lev <- max(augFit$.hat)
augFit$.hat == max_lev
augFit <- augment(fit)
head(augFit)
max_lev <- max(augFit$.hat)
augFit[augFit$.hat == max_lev]
augFit$.hat[augFit$.hat == max_lev]
augFit <- augment(fit)
head(augFit)
max_lev <- max(augFit$.hat)
augFit$.hat[augFit$.hat == max_lev]
augFit <- augment(fit)
head(augFit)
max_lev <- max(augFit$.hat)
augFit[augFit$.hat == max_lev, ]
augFit <- augment(fit)
head(augFit)
max_lev <- max(augFit$.hat)
augFit[augFit$.hat == max_lev, ]
augFit[augFit$.hat == max(augFit$.cooksd), ]
augFit <- augment(fit)
head(augFit)
max_lev <- max(augFit$.hat)
augFit[augFit$.hat == max_lev, ]
augFit[augFit$.cooksd == max(augFit$.cooksd), ]
fitmodel <- function(X1, X2, beta0, beta1, beta2){
n <- length(X1)
Y <- beta0 + beta1*X1 + beta2*X2 + rnorm(n, 0, 1) # Generate/calculate response
fit <- lm(Y ~ X1 + X2) # Fit the model
fit$coefficients # Return estimated coefficient values
}
# Step 1
beta0 <- 0.5 # define beta_0
beta1 <- 0.3 # define beta_1,
beta2 <- 0.7 # define beta_2
# Step 2
mu <- matrix(c(0,0)) # Set means for X_1, X_2
sigma1 <- matrix(c(1, 0, 0, 1), ncol = 2) # Cov Matrix: Cov(X_1, X_2) = 0
# Step 3
set.seed(1822) # Francis Galton born, invented regression concept
n <- 250
X <- mvrnorm(250, mu=c(0,0), Sigma=sigma1)
X1 <- X[,1]
X2 <- X[,2]
# Step 7
beta_estimates <- replicate(10000, fitmodel(X1, X2, beta0, beta1, beta2))
sd(beta_estimates[1,])
# Step 1
beta0 <- 0.5 # define beta_0
beta1 <- 0.3 # define beta_1,
beta2 <- 0.7 # define beta_2
# Step 2
mu <- matrix(c(0,0)) # Set means for X_1, X_2
sigma1 <- matrix(c(1, 0, 0, 1), ncol = 2) # Cov Matrix: Cov(X_1, X_2) = 0
# Step 3
set.seed(1822) # Francis Galton born, invented regression concept
n <- 250
X <- mvrnorm(250, mu=c(0,0), Sigma=sigma1)
X1 <- X[,1]
X2 <- X[,2]
# Step 7
beta_estimates <- replicate(10000, fitmodel(X1, X2, beta0, beta1, beta2))
augFit <- augment(fit)
augFit$species <- case0902$Species
head(augFit)
max_lev <- max(augFit$.hat)
augFit[augFit$.hat == max_lev, ]
augFit[augFit$.cooksd == max(augFit$.cooksd), ]
summary(fit)
#summary(fit)
# Uncorrelated
sigma1 <- matrix(c(1, 0, 0, 1), ncol = 2) # Cov Matrix: Cov(X_1, X_2) = 0
# Step 3
set.seed(1822) # Francis Galton born, invented regression concept
n <- 250
X <- mvrnorm(n, mu=c(0,0), Sigma=sigma1)
X1 <- X[,1]
X2 <- X[,2]
# Step 7
uncor_beta_estimates <- replicate(10000, fitmodel(X1, X2, beta0, beta1, beta2))
# Correlated
sigma2 <- matrix(c(1, 0.9, 0.9, 1), ncol = 2)
# Step 3
set.seed(1822) # Francis Galton born, invented regression concept
n <- 250
X <- mvrnorm(n, mu=c(0,0), Sigma=sigma2)
X1 <- X[,1]
X2 <- X[,2]
# Step 7
cor_beta_estimates <- replicate(10000, fitmodel(X1, X2, beta0, beta1, beta2))
results <- cbind(t(uncor_beta_estimates), t(cor_beta_estimates))
gg <- apply(results, 2, var)
gg[4:6]/gg[1:3]
colnames(results) <- paste("hat(beta)[", rep(0:2, 2), "]:", rep(c("Uncorrelated", "Correlated"), each = 3), sep = "")
results <- melt(results)
colnames(results) <- c("index", "Param", "Estimate")
results$beta <- sapply(strsplit(as.character(results$Param), ":"), "[[", i = 1)
results$data <- factor(sapply(strsplit(as.character(results$Param), ":"), "[[", i = 2), levels = c("Uncorrelated", "Correlated"))
qplot(Estimate, data = results) + facet_grid(data ~ beta, labeller = label_parsed) +  ylab("") +  theme(axis.ticks = element_blank(), axis.text.y = element_blank())
knitr::opts_chunk$set(echo = TRUE)
library(broom)
library(ggplot2)
library(MASS)
library(Sleuth3)
help(case0902)
head(case0902)
fit <- lm(Brain ~ Body + Gestation + Litter , data = case0902)
summary(fit)
augFit <- augment(fit)
augFit$species <- case0902$Species
head(augFit)
max_lev <- max(augFit$.hat)
augFit[augFit$.hat == max_lev, ]
augFit[augFit$.cooksd == max(augFit$.cooksd), ]
fitmodel <- function(X1, X2, beta0, beta1, beta2){
n <- length(X1)
Y <- beta0 + beta1*X1 + beta2*X2 + rnorm(n, 0, 1) # Generate/calculate response
fit <- lm(Y ~ X1 + X2) # Fit the model
fit$coefficients # Return estimated coefficient values
}
# Step 1
beta0 <- 0.5 # define beta_0
beta1 <- 0.3 # define beta_1,
beta2 <- 0.7 # define beta_2
# Step 2
mu <- matrix(c(0,0)) # Set means for X_1, X_2
sigma1 <- matrix(c(1, 0, 0, 1), ncol = 2) # Cov Matrix: Cov(X_1, X_2) = 0
# Step 3
set.seed(1822) # Francis Galton born, invented regression concept
n <- 250
X <- mvrnorm(250, mu=c(0,0), Sigma=sigma1)
X1 <- X[,1]
X2 <- X[,2]
# Step 7
beta_estimates <- replicate(10000, fitmodel(X1, X2, beta0, beta1, beta2))
sd(beta_estimates[1,])
#summary(fit)
# Uncorrelated
sigma1 <- matrix(c(1, 0, 0, 1), ncol = 2) # Cov Matrix: Cov(X_1, X_2) = 0
# Step 3
set.seed(1822) # Francis Galton born, invented regression concept
n <- 250
X <- mvrnorm(n, mu=c(0,0), Sigma=sigma1)
X1 <- X[,1]
X2 <- X[,2]
# Step 7
uncor_beta_estimates <- replicate(10000, fitmodel(X1, X2, beta0, beta1, beta2))
# Correlated
sigma2 <- matrix(c(1, 0.9, 0.9, 1), ncol = 2)
# Step 3
set.seed(1822) # Francis Galton born, invented regression concept
n <- 250
X <- mvrnorm(n, mu=c(0,0), Sigma=sigma2)
X1 <- X[,1]
X2 <- X[,2]
# Step 7
cor_beta_estimates <- replicate(10000, fitmodel(X1, X2, beta0, beta1, beta2))
results <- cbind(t(uncor_beta_estimates), t(cor_beta_estimates))
gg <- apply(results, 2, var)
gg[4:6]/gg[1:3]
colnames(results) <- paste("hat(beta)[", rep(0:2, 2), "]:", rep(c("Uncorrelated", "Correlated"), each = 3), sep = "")
results <- melt(results)
colnames(results) <- c("index", "Param", "Estimate")
results$beta <- sapply(strsplit(as.character(results$Param), ":"), "[[", i = 1)
results$data <- factor(sapply(strsplit(as.character(results$Param), ":"), "[[", i = 2), levels = c("Uncorrelated", "Correlated"))
qplot(Estimate, data = results) + facet_grid(data ~ beta, labeller = label_parsed) +  ylab("") +  theme(axis.ticks = element_blank(), axis.text.y = element_blank())
View(results)
View(sigma1)
View(sigma1)
View(X)
